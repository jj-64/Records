feat = names(feature_only)[i]
summary(aov(formula(paste(feat, "~ label")), data = feature_matrix))[[1]][["Pr(>F)"]][1]
i=5
feat = names(feature_only)[i]
summary(aov(formula(paste(feat, "~ label")), data = feature_matrix))[[1]][["Pr(>F)"]][1]
i=6
feat = names(feature_only)[i]
summary(aov(formula(paste(feat, "~ label")), data = feature_matrix))[[1]][["Pr(>F)"]][1]
for(i in 7:50){
feat = names(feature_only)[i]
print(summary(aov(formula(paste(feat, "~ label")), data = feature_matrix))[[1]][["Pr(>F)"]][1])
}
i
for(i in 51:55){
feat = names(feature_only)[i]
print(summary(aov(formula(paste(feat, "~ label")), data = feature_matrix))[[1]][["Pr(>F)"]][1])
}
i
feat
View(feature_only)
devtools::load_all(".")
## --- Generate
feature_matrix = create_feature_dataset(n_per_model = 10, T_val = c(50,100,150))
glimpse(feature_matrix)
## ANOVA for each feature H0: equal feature for all   H1: At least one is different
feature_only = feature_matrix[,!(colnames(feature_matrix) %in% c("label", "series_id"))]
anova_results <- sapply(names(feature_only), function(feat) {
summary(aov(formula(paste(feat, "~ label")), data = feature_matrix))[[1]][["Pr(>F)"]][1]
})
anova_results
p_values_anova <- data.frame(Feature = names(anova_results), p_value = anova_results)
p_values_anova[which(p_values_anova$p_value> 0.05),]
## ANOVA for each feature H0: equal feature for all   H1: At least one is different
feature_only = feature_matrix[,!(colnames(feature_matrix) %in% c("label", "series_id", "T_length"))]
anova_results <- sapply(names(feature_only), function(feat) {
summary(aov(formula(paste(feat, "~ label")), data = feature_matrix))[[1]][["Pr(>F)"]][1]
})
p_values_anova <- data.frame(Feature = names(anova_results), p_value = anova_results)
p_values_anova[which(p_values_anova$p_value> 0.05),]
## NonPramateric: Kruskal Test
kruskal_results <- sapply(names(feature_only), function(feat) {
kruskal.test(as.formula(paste(feat, "~ label")), data = feature_matrix)$p.value
})
p_values_Kruskal <- data.frame(Feature = names(kruskal_results), p_value = kruskal_results)
p_values_Kruskal[which(p_values_Kruskal$p_value> 0.05),]
#### 4.1. Quick NA summary
na_summary <- sapply(feature_matrix, function(x) sum(is.na(x)))
na_summary[na_summary > 0]
## --- Generate
feature_matrix = create_feature_dataset(n_per_model = 100, T_val = c(50,100,150))
save(feature_matrix, file = "data/feature_matrix.rda")
data("feature_matrix")
glimpse(feature_matrix)
## Summary of variables per Group
summary_by_group <- as.data.frame(feature_matrix%>%
group_by(label) %>%
summarise(across(where(is.numeric), list(mean = mean))))
print(summary_by_group)
## ANOVA for each feature H0: equal feature for all   H1: At least one is different
feature_only = feature_matrix[,!(colnames(feature_matrix) %in% c("label", "series_id", "T_length"))]
anova_results <- sapply(names(feature_only), function(feat) {
summary(aov(formula(paste(feat, "~ label")), data = feature_matrix))[[1]][["Pr(>F)"]][1]
})
p_values_anova <- data.frame(Feature = names(anova_results), p_value = anova_results)
p_values_anova[which(p_values_anova$p_value> 0.05),]
## NonPramateric: Kruskal Test
kruskal_results <- sapply(names(feature_only), function(feat) {
kruskal.test(as.formula(paste(feat, "~ label")), data = feature_matrix)$p.value
})
p_values_Kruskal <- data.frame(Feature = names(kruskal_results), p_value = kruskal_results)
p_values_Kruskal[which(p_values_Kruskal$p_value> 0.05),]
#### 4.1. Quick NA summary
na_summary <- sapply(feature_matrix, function(x) sum(is.na(x)))
na_summary[na_summary > 0]
# Replace NAs with reasonable substitutes (median or -999 if extreme)
feature_matrix=feature_matrix[complete.cases(feature_matrix),]
# First get feature matrix (numerics only)
feature_names <- setdiff(names(feature_matrix), c("series_id", "label", "series"))
#### 4.2. Remove near-zero variance predictors
nzv <- nearZeroVar(X, saveMetrics = TRUE)
#### 4.2. Remove near-zero variance predictors
nzv <- nearZeroVar(feature_only, saveMetrics = TRUE)
nzv
if (any(nzv$nzv)) {
cat("Near zero variance features:\n")
print(rownames(nzv)[nzv$nzv])
X<- X[, !nzv$nzv]
}
#### 4.2. Remove near-zero variance predictors
nzv <- nearZeroVar(feature_only, saveMetrics = TRUE)
if (any(nzv$nzv)) {
cat("Near zero variance features:\n")
print(rownames(nzv)[nzv$nzv])
feature_only<- feature_only[, !nzv$nzv]
}
#### 4.3. Correlation-based filtering
corr_matrix <- cor(feature_only)
high_corr <- findCorrelation(corr_matrix, cutoff = 0.9)
high_corr_pairs <- which(abs(corr_matrix) > 0.9 & abs(corr_matrix) < 1, arr.ind = TRUE)
#findCorrelation(corr_matrix, cutoff = 0.9, verbose=TRUE, names = TRUE)
if (length(high_corr) > 0) {
cat("Highly correlated feature pairs (>0.9):\n")
apply(high_corr_pairs, 1, function(idx) cat(rownames(corr_matrix)[idx[1]], "<->", colnames(corr_matrix)[idx[2]], "\n"))
} else {
cat("No extremely high correlations (>0.9) found.\n")
}
length(high_corr)
high_corr
#### 4.4.VIF check
# We'll run a quick linear model on one-vs-rest (use multicollinearity check on all predictors)
# Fit a dummy lm to calculate VIF (use label dummy as numeric)
vif_df <- feature_only
# Add a pseudo-response to allow lm
vif_df$y_tmp <- as.numeric(as.factor(feature_matrix$label))
lm_tmp <- lm(y_tmp ~ ., data = vif_df)
vif_vals <- car::vif(lm_tmp)
lm_tmp
car::vif(lm_tmp)
vif_df$y_tmp
vif_df
vif_df$y_tmp
lm(y_tmp ~ ., data = vif_df)
lm_tmp <- lm(y_tmp ~ ., data = vif_df)
vif_vals <- car::vif(lm_tmp)
#### 4.5. PCA for dimensionality reduction
X_numeric_matrix <- scale(feature_only)
pca_res <- prcomp(X_numeric_matrix, center = TRUE, scale. = TRUE)
# examine explained variance
explained <- summary(pca_res)$importance[2, ]
cumulative <- summary(pca_res)$importance[3, ]
# choose number of PCs to explain e.g. 90%
n_pc_90 <- which(cumulative >= 0.90)[1]
cat("Number of principal components explaining >= 90% variance:", n_pc_90, "\n")
df= feature_matrix
label_col = "label"
id_col = "series_id"
do_parallel = FALSE
## Prepare
df <- df %>% as.data.frame()
df = na.omit(df)
rownames(df) <- df[[id_col]]
y <- as.factor(df[[label_col]])
X_df <- df %>% dplyr::select(-one_of(label_col, id_col))
## partition into train/test (we'll use 80/20 stratified)
train_index <- createDataPartition(y, p = 0.8, list = FALSE)
train_data <- X_df[train_index, ]
train_label <- y[train_index]
test_data <- X_df[-train_index, ]
test_label <- y[-train_index]
# caret control
trctrl <- trainControl(method = "repeatedcv",
number = 5,
repeats = 2,
classProbs = TRUE,
summaryFunction = multiClassSummary,
savePredictions = "final",
verboseIter = FALSE)
models_list <- list()
results <- list()
# 1) multinom (multinomial logistic using nnet::multinom)
cat("Training multinom...\n")
m_multinom <- train(x = train_data, y = train_label,
method = "multinom",
trControl = trctrl,
trace = FALSE)
models_list$multinom <- m_multinom
m_multinom
# 2) glmnet (multinomial)
cat("Training glmnet (multinomial)...\n")
tunegrid_glmnet <- expand.grid(alpha = c(0, 0.5, 1), lambda = 10^seq(-3, 1, length = 10))
m_glmnet <- train(x = train_data, y = train_label,
method = "glmnet",
tuneGrid = tunegrid_glmnet,
trControl = trctrl,
family = "multinomial")
m_glmnet
models_list$glmnet <- m_glmnet
# 3) random forest
#set.seed(seed)
cat("Training randomForest...\n")
m_rf <- train(x = train_data, y = train_label,
method = "rf",
trControl = trctrl,
importance = TRUE,
tuneLength = 5)
models_list$rf <- m_rf
m_rf
# 5) SVM radial
#set.seed(seed)
cat("Training SVM radial...\n")
m_svm <- train(x = train_data, y = train_label,
method = "svmRadial",
trControl = trctrl,
tuneLength = 4)
models_list$svm <- m_svm
m_svm <- train(x = train_data, y = train_label,
method = "svmRadial",
trControl = trctrl,
tuneLength = 4)
models_list$svm <- m_svm
m_knn <- train(x = train_data, y = train_label,
method = "knn",
trControl = trctrl,
tuneLength = 5)
models_list$knn <- m_knn
# 7) naive Bayes
#set.seed(seed)
cat("Training naiveBayes...\n")
m_nb <- train(x = train_data, y = train_label,
method = "naive_bayes",
trControl = trctrl,
tuneLength = 3)
models_list$nb <- m_nb
# 8) neural net (nnet)
#set.seed(seed)
cat("Training nnet...\n")
m_nnet <- train(x = train_data, y = train_label,
method = "nnet",
trControl = trctrl,
tuneLength = 4,
trace = FALSE)
models_list$nnet <- m_nnet
# Evaluate on test set for each model
evaluate_model <- function(model, test_data, test_label) {
preds <- predict(model, newdata = test_data)
probs <- tryCatch(predict(model, newdata = test_data, type = "prob"), error = function(e) NULL)
cm <- confusionMatrix(preds, test_label)
# multiclass AUC: average of one-vs-rest AUC if probs available
auc_avg <- NA
if (!is.null(probs)) {
# compute multiclass AUC via micro-average: average of pairwise or one-vs-rest AUC
labels <- levels(test_label)
aucs <- c()
for (lab in labels) {
true_bin <- ifelse(test_label == lab, 1, 0)
roc_obj <- tryCatch(pROC::roc(true_bin, probs[, lab], quiet = TRUE), error = function(e) NULL)
if (!is.null(roc_obj)) {
aucs <- c(aucs, pROC::auc(roc_obj))
}
}
if (length(aucs) > 0) auc_avg <- mean(aucs)
}
list(confusion = cm, auc = auc_avg, predictions = preds, probs = probs)
}
for (mname in names(models_list)) {
cat("Evaluating", mname, "on test data...\n")
results[[mname]] <- evaluate_model(models_list[[mname]], test_data, test_label)
}
list(models = models_list, results = results, train_index = train_index,
train_data = train_data, train_label = train_label,
test_data = test_data, test_label = test_label)
train_=list(models = models_list, results = results, train_index = train_index,
train_data = train_data, train_label = train_label,
test_data = test_data, test_label = test_label)
res_selected =list(models = models_list, results = results, train_index = train_index,
train_data = train_data, train_label = train_label,
test_data = test_data, test_label = test_label)
# Train using PCA features
cat("Training models on PCA features...\n")
# We'll build a summary table of performance metrics: accuracy, kappa, multiclass AUC (if available)
summarize_results <- function(res) {
out <- tibble()
for (mname in names(res$models)) {
cm <- res$results[[mname]]$confusion
auc <- res$results[[mname]]$auc
acc <- cm$overall["Accuracy"]
kappa <- cm$overall["Kappa"]
out <- bind_rows(out, tibble(method = mname, accuracy = as.numeric(acc), kappa = as.numeric(kappa), auc = as.numeric(auc)))
}
out %>% arrange(desc(accuracy))
}
summary_selected <- summarize_results(res_selected)
print(summary_selected)
install.packages("randomForest")
install.packages("randomForest")
library("randomForest")
rf_model <- randomForest(train_label ~ ., data = train_data, ntree = 500, mtry = sqrt(ncol(train_data) - 1))
print(rf_model) # View model summary and OOB error rate
predictions <- predict(rf_model, newdata = test_data)
confusion_matrix <- table(test_data$Species, predictions)
confusion_matrix <- table(test_label, predictions)
print(confusion_matrix)
accuracy <- sum(diag(confusion_matrix)) / sum(confusion_matrix)
print(paste("Accuracy:", accuracy))
varImp(rf_model)
plot(varImp(rf_model))
sort(varImp(rf_model))
x=(varImp(rf_model))
View(x)
x=  DTRW_series(10, "norm", loc=0, sd=5)
x
mean(x)
y=x/max(x)
mean(y)
sd(x); sd(y)
y
rec_values(x)
rec_values(y)
rec_times(y)
rec_times(x)
devtools::load_all(".")
## --- Generate
feature_matrix = create_feature_dataset(n_per_model = 100, T_val = c(50,100,150))
devtools::load_all(".")
View(feature_matrix)
## Summary of variables per Group
summary_by_group <- as.data.frame(feature_matrix%>%
group_by(label) %>%
summarise(across(where(is.numeric), list(mean = mean))))
print(summary_by_group)
## ANOVA for each feature H0: equal feature for all   H1: At least one is different
feature_only = feature_matrix[,!(colnames(feature_matrix) %in% c("label", "series_id", "T_length"))]
anova_results <- sapply(names(feature_only), function(feat) {
summary(aov(formula(paste(feat, "~ label")), data = feature_matrix))[[1]][["Pr(>F)"]][1]
})
p_values_anova <- data.frame(Feature = names(anova_results), p_value = anova_results)
p_values_anova[which(p_values_anova$p_value> 0.05),]
## NonPramateric: Kruskal Test
kruskal_results <- sapply(names(feature_only), function(feat) {
kruskal.test(as.formula(paste(feat, "~ label")), data = feature_matrix)$p.value
})
p_values_Kruskal <- data.frame(Feature = names(kruskal_results), p_value = kruskal_results)
p_values_Kruskal[which(p_values_Kruskal$p_value> 0.05),]
devtools::load_all(".")
## --- Generate
feature_matrix = create_feature_dataset(n_per_model = 10, T_val = c(50,100,150))
devtools::load_all(".")
n_per_model = 10
T_val = c(50,100,150)
data <- generate_series_multiple(n_per_model, T_vals, normalized = TRUE)
## --- Generate
feature_matrix = create_feature_dataset(n_per_model = 10, T_vals = c(50,100,150))
data <- generate_series_multiple(n_per_model, T_vals, normalized = TRUE)
T_vals = c(100, 200, 500)
data <- generate_series_multiple(n_per_model, T_vals, normalized = TRUE)
View(data)
n <- length(data$series)
rm(T_val)
table(data$labels)
devtools::load_all(".")
## --- Generate
feature_matrix = create_feature_dataset(n_per_model = 10, T_vals = c(50,100,150))
data <- generate_series_multiple(n_per_model, T_vals, normalized = TRUE)
n_per_model
data <- generate_series_multiple(n_per_model, T_vals, normalized = TRUE)
n <- length(data$series)
feature_list <- vector("list", n)
i=1
x <- data$series[[i]]
# extract all your features
f <- extract_all_features(x)
data$series
## ---- DTRW
i = 1
s <- generate_series(
DTRW_series,
series_args = list(dist = "norm", mean = 0, sd = 1),
T_val = T_val
)
T_val = 50
s <- generate_series(
DTRW_series,
series_args = list(dist = "norm", mean = 0, sd = 1),
T_val = T_val
)
if(length(rec_gaps(s)) <2 ) next;
length(rec_gaps(s))
s <- generate_series(
DTRW_series,
series_args = list(dist = "norm", mean = 0, sd = 1),
T_val = T_val
)
length(rec_gaps(s))
s/max(s)
normalized = TRUE
ifelse(normalized == TRUE, s/max(s), s)
s/max(s)
s
if(normalized) {s/max(s) } else {s}
devtools::load_all(".")
## --- Generate
feature_matrix = create_feature_dataset(n_per_model = 10, T_vals = c(50,100,150))
glimpse(feature_matrix)
## ANOVA for each feature H0: equal feature for all   H1: At least one is different
feature_only = feature_matrix[,!(colnames(feature_matrix) %in% c("label", "series_id", "T_length"))]
anova_results <- sapply(names(feature_only), function(feat) {
summary(aov(formula(paste(feat, "~ label")), data = feature_matrix))[[1]][["Pr(>F)"]][1]
})
p_values_anova <- data.frame(Feature = names(anova_results), p_value = anova_results)
p_values_anova[which(p_values_anova$p_value> 0.05),]
## Summary of variables per Group
summary_by_group <- as.data.frame(feature_matrix%>%
group_by(label) %>%
summarise(across(where(is.numeric), list(mean = mean))))
print(summary_by_group)
View(feature_matrix)
## Summary of variables per Group
summary_by_group <- as.data.frame(feature_matrix%>%
group_by(label) %>%
summarise(across(where(is.numeric), list(mean = mean))))
print(summary_by_group)
## ANOVA for each feature H0: equal feature for all   H1: At least one is different
feature_only = feature_matrix[,!(colnames(feature_matrix) %in% c("label", "series_id", "T_length"))]
anova_results <- sapply(names(feature_only), function(feat) {
summary(aov(formula(paste(feat, "~ label")), data = feature_matrix))[[1]][["Pr(>F)"]][1]
})
p_values_anova <- data.frame(Feature = names(anova_results), p_value = anova_results)
p_values_anova[which(p_values_anova$p_value> 0.05),]
## NonPramateric: Kruskal Test
kruskal_results <- sapply(names(feature_only), function(feat) {
kruskal.test(as.formula(paste(feat, "~ label")), data = feature_matrix)$p.value
})
p_values_Kruskal <- data.frame(Feature = names(kruskal_results), p_value = kruskal_results)
p_values_Kruskal[which(p_values_Kruskal$p_value> 0.05),]
#### 4.1. Quick NA summary
na_summary <- sapply(feature_matrix, function(x) sum(is.na(x)))
na_summary[na_summary > 0]
# Replace NAs with reasonable substitutes (median or -999 if extreme)
feature_matrix=feature_matrix[complete.cases(feature_matrix),]
#### 4.2. Remove near-zero variance predictors
nzv <- nearZeroVar(feature_only, saveMetrics = TRUE)
if (any(nzv$nzv)) {
cat("Near zero variance features:\n")
print(rownames(nzv)[nzv$nzv])
feature_only<- feature_only[, !nzv$nzv]
}
#### 4.3. Correlation-based filtering
corr_matrix <- cor(feature_only)
high_corr <- findCorrelation(corr_matrix, cutoff = 0.9)
high_corr_pairs <- which(abs(corr_matrix) > 0.9 & abs(corr_matrix) < 1, arr.ind = TRUE)
#findCorrelation(corr_matrix, cutoff = 0.9, verbose=TRUE, names = TRUE)
if (length(high_corr) > 0) {
cat("Highly correlated feature pairs (>0.9):\n")
apply(high_corr_pairs, 1, function(idx) cat(rownames(corr_matrix)[idx[1]], "<->", colnames(corr_matrix)[idx[2]], "\n"))
} else {
cat("No extremely high correlations (>0.9) found.\n")
}
View(corr_matrix)
#### 4.4.VIF check
# We'll run a quick linear model on one-vs-rest (use multicollinearity check on all predictors)
# Fit a dummy lm to calculate VIF (use label dummy as numeric)
vif_df <- feature_only
# Add a pseudo-response to allow lm
vif_df$y_tmp <- as.numeric(as.factor(feature_matrix$label))
lm_tmp <- lm(y_tmp ~ ., data = vif_df)
vif_vals <- car::vif(lm_tmp)
x=0.6
x^2
0.6-0.36
ls(Records)
ls("Records")
usethis::use_testthat()
usethis::use_test("is_rec")
git add .
devtools::run_examples()
devtools::run_examples()
devtools::load_all(".")
devtools::load_all(".")
rec_count_stats("iid", stat = "mean", T = 100)
rec_count_stats("YNM", stat = "var", T = 200, gamma = 1.1)
rec_count_stats("YNM", stat = c("mean","var"), T = 200, gamma = 1.1)
model = "YNM"
stat = c("mean", "var")
T = 200
gamma = 1.1
stat <- match.arg(stat)
if (is.null(record_registry[[model]]))
stop("Unknown model: ", model)
entry <- record_registry[[model]]
entry
# Check required extra arguments
missing <- setdiff(entry$required_args, names(list(...)))
# Check required extra arguments
missing <- setdiff(entry$required_args, names(list(gamma = 1.1)))
if (length(missing) > 0) {
stop("Model '", model, "' requires arguments: ",
paste(missing, collapse = ", "))
}
entry
entry$mean_fun
fun(T = T, gamma=1.1)
fun <- if ("mean" %in% stat) entry$mean_fun
fun(T = T, gamma=1.1)
rec_count_stats("YNM", stat = c("mean"), T = 200, gamma = 1.1)
devtools::load_all(".")
rec_count_stats("LDM", stat="dist", T=100, m=7, theta=0.4, scale=1)
rec_rate_LDM
devtools::load_all(".")
rec_count_stats("LDM", stat="dist", T=100, m=7, theta=0.4, scale=1)
rec_count_stats("LDM", stat="dist", T=25, m=c(1:5), theta=0.4, scale=1)
record_stats("iid", stat="dist", T=50, m=4)
rec_count_stats("iid", stat="dist", T=50, m=4)
gmp::Stirling2(n=5, K= 0.5)
gmp::Stirling2(n=0.5, K= 5)
gmp::Stirling2(n=0.5, k= 5)
gmp::Stirling2(n=2, k= 0.5)
gmp::Stirling2(n=2, k= 1)
gmp::Stirling2(n=2, k= 2)
gmp::Stirling2(n=2, k= 3)
gmp::Stirling2(n=5, k= 0.5)
devtools::load_all(".")
rec_count_stats("DTRW", stat="dist", T=200, m=10, approx=TRUE)
devtools::load_all(".")
devtools::load_all(".")
devtools::load_all(".")
devtools::load_all(".")
stopifnot(-2>0)
devtools::load_all(".")
devtools::load_all(".")
devtools::load_all(".")
YNM_series(T, 1.2, dist="gumbel", loc=0, scale=1)
devtools::load_all(".")
