sum(apply( feature_only, 2, FUN = is.finite))
summary(feature_only)
## fix LogLik values
feature_matrix[grep("^logLik_", names(feature_matrix))] <-
lapply(feature_matrix[grep("^logLik_", names(feature_matrix))], function(x) {
x[x < -1e5] <- -1e5#Inf
x[!is.finite(x)] <- -1e5
x
})
## Feature only
feature_only = feature_matrix[,!(colnames(feature_matrix) %in% c( "series_id", "T_length"))]
########################################################################
# End of script
###############################RF #########################################
rf <- randomForest(label ~. , data = feature_only)
feature_only = na.omit(feature_only)
########################################################################
# End of script
###############################RF #########################################
rf <- randomForest(label ~. , data = feature_only)
########################################################################
# End of script
###############################RF #########################################
rf <- randomForest(label ~. , data = feature_only)
table(feature_only$label)
feature_only$label = as.factor(feature_only$label)
########################################################################
# End of script
###############################RF #########################################
rf <- randomForest(label ~. , data = feature_only)
print(rf)
rf_model= rf
predictions <- predict(rf_model, feature_matrix)
confusionMatrix(predictions, feature_matrix$label)
predictions <- predict(rf_model, feature_matrix)
predictions
confusionMatrix(predictions, feature_matrix$label)
feature_matrix$label = as.factor(feature_matrix$label)
confusionMatrix(predictions, feature_matrix$label)
print(rf_tuned)
print(rf_model)
########################################################################
# End of script
###############################RF #########################################
rf_model <- randomForest(label ~. , data = feature_only,  ntree = 500, mtry = 3)
print(rf_model)
importance(rf_model)
varImpPlot(rf_model)
sort(importance(rf_model))
importance(rf_model)
as.data.frame(importance(rf_model))
var_imp = as.data.frame(importance(rf_model))
View(var_imp)
series <- as.numeric(series)
series = LDM_series(100, 0.2, "weibull", shape=1, scale=2)
series <- as.numeric(series)
n <- length(series)
if (n < 10) stop("Series too short for stable features")
if (length(rec_gaps(series)) <2) warning("No records found")
## theta hat
time <- seq_len(length(series))
lmfit <- lm(series ~ time)
theta_hat = as.numeric(coef(lmfit)[2])
## gamma hat
gamma_hat = estimate_model_param(series, method="mle_indicator", model = "YNM", min= 1, max=5, step = 0.001, approximate = FALSE)$param
## record data
data_rec = data.frame(rec_values = rec_values(series),
rec_times = rec_times(series),
time = length(series),
theta = theta_hat,
gamma = gamma_hat)
## measures
mean_all = mean(series)
var_all = var(series)
shape_all = abs(skewness(series))
mean_rec = mean(rec_values(series))
var_rec =  var(rec_values(series))
shape_rec = abs(skewness(rec_values(series)))
## Classical -  all
logLik_all_iid_gumbel = logLik_records(model = "iid", obs_type = "all",
dist = "gumbel", data = series,
params = c(loc = mean_all, scale=var_all))
logLik_all_iid_norm = logLik_records(model = "iid", obs_type = "all",
dist = "norm", data = series,
params = c(mean = mean_all, sd=sqrt(var_all)) )
logLik_all_iid_frechet = logLik_records(model = "iid", obs_type = "all",
dist = "frechet", data = series,
params = c(shape = shape_all, scale=var_all))
logLik_all_iid_weibull = logLik_records(model = "iid", obs_type = "all",
dist = "weibull", data = series,
params = c(shape = shape_all, scale=var_all))
## Classical - Rn
logLik_rec_iid_norm = logLik_records(model = "iid", obs_type = "records",
dist = "norm", data = data_rec,
params = c(mean = mean_rec, sd= sqrt(var_rec)) )
logLik_rec_iid_gumbel = logLik_records(model = "iid", obs_type = "records",
dist = "gumbel", data = data_rec,
params = c(loc = mean_rec, scale=var_rec))
logLik_rec_iid_frechet = logLik_records(model = "iid", obs_type = "records",
dist = "frechet", data = data_rec,
params = c(shape=shape_rec, scale=var_rec))
logLik_rec_iid_weibull = logLik_records(model = "iid", obs_type = "records",
dist = "weibull", data = data_rec,
params =  c(shape=shape_rec, scale=var_rec))
## DTRW - all
logLik_all_DTRW_norm = logLik_records(model = "DTRW", obs_type = "all",
dist = "norm", data = series,
params = c(mean = mean_all, sd= sqrt(var_all)))
logLik_all_DTRW_cauchy = logLik_records(model = "DTRW", obs_type = "all",
dist = "cauchy", data = series,
params = c(loc = mean_all, scale=var_all))
## DTRW - rec
logLik_rec_DTRW_norm = logLik_records(model = "DTRW", obs_type = "records",
dist = "norm", data = data_rec,
params = c(mean = mean_rec, sd= sqrt(var_all) ) )
logLik_rec_DTRW_cauchy = logLik_records(model = "DTRW", obs_type = "records",
dist = "cauchy", data = data_rec,
params = c(loc = mean_rec, scale=var_all ))
## LDM - Xt
logLik_all_LDM_norm = logLik_records(model = "LDM", obs_type = "all",
dist = "norm", data = series,
params = c(theta = theta_hat, mean = mean_all, sd=sqrt(var_all)))
logLik_all_LDM_gumbel = logLik_records(model = "LDM", obs_type = "all",
dist = "gumbel", data = series,
params = c(theta = theta_hat, loc = mean_all, scale=var_all))
logLik_all_LDM_frechet = logLik_records(model = "LDM", obs_type = "all",
dist = "frechet", data = series,
params = c(theta = theta_hat, shape=shape_all, scale=var_all))
logLik_all_LDM_weibull = logLik_records(model = "LDM", obs_type = "all",
dist = "weibull", data = series,
params = c(theta = theta_hat, shape=shape_all, scale=var_all))
## LDM - rec
logLik_rec_LDM_norm = logLik_records(model = "LDM", obs_type = "records",
dist = "norm", data = data_rec,
params = c(theta = theta_hat, mean = mean_rec, sd= sqrt(var_rec)))
logLik_rec_LDM_gumbel = logLik_records(model = "LDM", obs_type = "records",
dist = "gumbel", data = data_rec,
params = c(theta = theta_hat, loc = mean_rec, scale=var_rec))
logLik_rec_LDM_frechet = logLik_records(model = "LDM", obs_type = "records",
dist = "frechet", data = data_rec,
params = c(theta = theta_hat, shape=shape_rec, scale=var_rec))
logLik_rec_LDM_weibull = logLik_records(model = "LDM", obs_type = "records",
dist = "weibull", data = data_rec,
params = c(theta = theta_hat, shape = shape_rec, scale=var_rec))
## YNM - Xt
logLik_all_YNM_norm = logLik_records(model = "YNM", obs_type = "all",
dist = "norm", data = series,
params = c(gamma = gamma_hat, mean = mean_all, sd=sqrt(var_all)))
logLik_all_YNM_gumbel = logLik_records(model = "YNM", obs_type = "all",
dist = "gumbel", data = series,
params = c(gamma = gamma_hat, loc = mean_all, scale=var_all))
logLik_all_YNM_frechet = logLik_records(model = "YNM", obs_type = "all",
dist = "frechet", data = series,
params = c(gamma = gamma_hat, shape=shape_all, scale=var_all))
logLik_all_YNM_weibull = logLik_records(model = "YNM", obs_type = "all",
dist = "weibull", data = series,
params = c(gamma = gamma_hat, shape =shape_all, scale=var_all))
## YNM - rec
logLik_rec_YNM_norm = logLik_records(model = "YNM", obs_type = "records",
dist = "norm", data = data_rec,
params = c(gamma = gamma_hat, mean = mean_rec, sd= sqrt(var_rec)) )
logLik_rec_YNM_gumbel = logLik_records(model = "YNM", obs_type = "records",
dist = "gumbel", data = data_rec,
params = c(gamma = gamma_hat, loc = mean_rec, scale=var_rec))
logLik_rec_YNM_frechet = logLik_records(model = "YNM", obs_type = "records",
dist = "frechet", data = data_rec,
params = c(gamma = gamma_hat, shape=shape_rec, scale=var_rec))
logLik_rec_YNM_weibull = logLik_records(model = "YNM", obs_type = "records",
dist = "weibull", data = data_rec,
params = c(gamma = gamma_hat, shape=shape_rec, scale=var_rec))
Log_values = c(
logLik_all_iid_gumbel =   logLik_all_iid_gumbel,
logLik_all_iid_norm =   logLik_all_iid_norm,
logLik_all_iid_frechet = logLik_all_iid_frechet,
logLik_all_iid_weibull = logLik_all_iid_weibull,
logLik_rec_iid_gumbel =   logLik_rec_iid_gumbel,
logLik_rec_iid_norm =   logLik_rec_iid_norm,
logLik_rec_iid_frechet = logLik_rec_iid_frechet,
logLik_rec_iid_weibull = logLik_rec_iid_weibull,
logLik_all_DTRW_norm = logLik_all_DTRW_norm,
logLik_all_DTRW_cauchy = logLik_all_DTRW_cauchy,
logLik_rec_DTRW_norm = logLik_rec_DTRW_norm,
logLik_rec_DTRW_cauchy = logLik_rec_DTRW_cauchy,
logLik_all_LDM_norm = logLik_all_LDM_norm,
logLik_all_LDM_gumbel = logLik_all_LDM_gumbel,
logLik_all_LDM_frechet = logLik_all_LDM_frechet,
logLik_all_LDM_weibull = logLik_all_LDM_weibull,
logLik_rec_LDM_norm = logLik_rec_LDM_norm,
logLik_rec_LDM_gumbel = logLik_rec_LDM_gumbel,
logLik_rec_LDM_frechet = logLik_rec_LDM_frechet,
logLik_rec_LDM_weibull = logLik_rec_LDM_weibull,
logLik_all_YNM_norm = logLik_all_YNM_norm,
logLik_all_YNM_gumbel = logLik_all_YNM_gumbel,
logLik_all_YNM_frechet = logLik_all_YNM_frechet,
logLik_all_YNM_weibull = logLik_all_YNM_weibull,
logLik_rec_YNM_norm = logLik_rec_YNM_norm,
logLik_rec_YNM_gumbel = logLik_rec_YNM_gumbel,
logLik_rec_YNM_frechet = logLik_rec_YNM_frechet,
logLik_rec_YNM_weibull = logLik_rec_YNM_weibull
)
which.max(Log_values)
devtools::load_all(".")
logLik_all_DTRW_cauchy = logLik_records(model = "DTRW", obs_type = "all",
dist = "cauchy", data = series,
params = c(loc = mean_all, scale=var_all))
Log_values = c(
logLik_all_iid_gumbel =   logLik_all_iid_gumbel,
logLik_all_iid_norm =   logLik_all_iid_norm,
logLik_all_iid_frechet = logLik_all_iid_frechet,
logLik_all_iid_weibull = logLik_all_iid_weibull,
logLik_rec_iid_gumbel =   logLik_rec_iid_gumbel,
logLik_rec_iid_norm =   logLik_rec_iid_norm,
logLik_rec_iid_frechet = logLik_rec_iid_frechet,
logLik_rec_iid_weibull = logLik_rec_iid_weibull,
logLik_all_DTRW_norm = logLik_all_DTRW_norm,
logLik_all_DTRW_cauchy = logLik_all_DTRW_cauchy,
logLik_rec_DTRW_norm = logLik_rec_DTRW_norm,
logLik_rec_DTRW_cauchy = logLik_rec_DTRW_cauchy,
logLik_all_LDM_norm = logLik_all_LDM_norm,
logLik_all_LDM_gumbel = logLik_all_LDM_gumbel,
logLik_all_LDM_frechet = logLik_all_LDM_frechet,
logLik_all_LDM_weibull = logLik_all_LDM_weibull,
logLik_rec_LDM_norm = logLik_rec_LDM_norm,
logLik_rec_LDM_gumbel = logLik_rec_LDM_gumbel,
logLik_rec_LDM_frechet = logLik_rec_LDM_frechet,
logLik_rec_LDM_weibull = logLik_rec_LDM_weibull,
logLik_all_YNM_norm = logLik_all_YNM_norm,
logLik_all_YNM_gumbel = logLik_all_YNM_gumbel,
logLik_all_YNM_frechet = logLik_all_YNM_frechet,
logLik_all_YNM_weibull = logLik_all_YNM_weibull,
logLik_rec_YNM_norm = logLik_rec_YNM_norm,
logLik_rec_YNM_gumbel = logLik_rec_YNM_gumbel,
logLik_rec_YNM_frechet = logLik_rec_YNM_frechet,
logLik_rec_YNM_weibull = logLik_rec_YNM_weibull
)
Max_lik = which.max(Log_values)
Max_lik
name(Max_lik)
names(Max_lik)
names(Max_lik)[1]
substr(names(Max_lik)[1])
substr("logLik_rec_DTRW_norm", start = 12)
substr("logLik_rec_DTRW_norm", start = 12, stop = 15)
substr("logLik_rec_DTRW_norm", start = 12, stop = 20)
substr("logLik_rec_DTRW_norm", start = 12, stop = 21)
substr("logLik_rec_DTRW_norm", start = 12, stop = 25)
b =  extract_tsfeatures(x)
b =  extract_tsfeatures(series)
b
# print("Extract custom features ...")
a = extract_custom_features(x)
# print("Extract custom features ...")
a = extract_custom_features(series)
a
# message("Extract LogLik features ...")
c = extract_LogLik_features(x)
# message("Extract LogLik features ...")
c = extract_LogLik_features(series)
c
c(a, b, c)
which.max(c)
devtools::load_all(".")
devtools::load_all(".")
x=series
# message("Extract LogLik features ...")
c = extract_LogLik_features(x)
which.max(c)
names(which.max(c))
names(which.max(c)[1])
substr(names(which.max(c)[1]),start = 12, stop = 25) )
substr(names(which.max(c)[1]),start = 12, stop = 25)
Max_lik = substr(names(which.max(c)[1]),start = 12, stop = 25)
c(a, b, c, Max_lik)
c(a, b, c, Max_lik = Max_lik)
devtools::load_all(".")
# ----- 3. Build labeled feature_matrix of features ---------------------------------------
## --- Generate
simulated_data = create_feature_dataset(n_per_model = 50, T_vals = c(50,100,150))
devtools::load_all(".")
# ----- 3. Build labeled feature_matrix of features ---------------------------------------
## --- Generate
simulated_data = create_feature_dataset(n_per_model = 50, T_vals = c(50,100,150))
feature_matrix  = as.data.frame(simulated_data$feature)
## fix LogLik values
feature_matrix[grep("^logLik_", names(feature_matrix))] <-
lapply(feature_matrix[grep("^logLik_", names(feature_matrix))], function(x) {
x[x < -1e5] <- -1e5#Inf
x[!is.finite(x)] <- -1e5
x
})
########################################################################
# End of script
###############################RF #########################################
## Feature only
feature_matrix$label = as.factor(feature_matrix$label)
feature_only = feature_matrix[,!(colnames(feature_matrix) %in% c("series_id", "T_length"))]
rf_model <- randomForest(label ~. , data = feature_only,  ntree = 500, mtry = 3)
feature_only = na.omit(feature_only)
rf_model <- randomForest(label ~. , data = feature_only,  ntree = 500, mtry = 3)
print(rf_model)
predictions <- predict(rf_model, feature_matrix)
confusionMatrix(predictions, feature_matrix$label)
var_imp = as.data.frame(importance(rf_model))
View(var_imp)
View(feature_only)
table(feature_matrix$label, feature_matrix$Max_logLik)
prop.table(table(feature_matrix$label, feature_matrix$Max_logLik))
round(prop.table(table(feature_matrix$label, feature_matrix$Max_logLik))*100,1)
round(prop.table(table(feature_matrix$label, feature_matrix$Max_logLik),1)*100,1)
Log_values
plot(series)
rec_values(series)
# ----- 3. Build labeled feature_matrix of features ---------------------------------------
## --- Generate
simulated_data = create_feature_dataset(n_per_model = 50, T_vals = c(50,100,150), FALSE)
devtools::load_all(".")
# ----- 3. Build labeled feature_matrix of features ---------------------------------------
## --- Generate
simulated_data = create_feature_dataset(n_per_model = 50, T_vals = c(50,100,150), FALSE)
raw_data = simulated_data$data
feature_matrix  = as.data.frame(simulated_data$feature)
########################################################################
# End of script
###############################RF #########################################
## Feature only
feature_matrix$label = as.factor(feature_matrix$label)
feature_only = feature_matrix[,!(colnames(feature_matrix) %in% c("series_id", "T_length"))]
feature_only = na.omit(feature_only)
rf_model <- randomForest(label ~. , data = feature_only,  ntree = 500, mtry = 3)
feature_only = na.omit(feature_only)
rf_model <- randomForest(label ~. , data = feature_only,  ntree = 500, mtry = 3)
########################################################################
# End of script
###############################RF #########################################
## Feature only
feature_matrix$label = as.factor(feature_matrix$label)
feature_only = feature_matrix[,!(colnames(feature_matrix) %in% c("series_id", "T_length"))]
feature_only = na.omit(feature_only)
rf_model <- randomForest(label ~. , data = feature_only,  ntree = 500, mtry = 3)
rf_model <- randomForest(label ~. , data = feature_only,  ntree = 500, mtry = 9)
View(feature_only)
## fix LogLik values
feature_matrix[grep("^logLik_", names(feature_matrix))] <-
lapply(feature_matrix[grep("^logLik_", names(feature_matrix))], function(x) {
x[x < -1e5] <- -1e5#Inf
x[!is.finite(x)] <- -1e5
x
})
########################################################################
# End of script
###############################RF #########################################
## Feature only
feature_matrix$label = as.factor(feature_matrix$label)
feature_only = feature_matrix[,!(colnames(feature_matrix) %in% c("series_id", "T_length"))]
feature_only = na.omit(feature_only)
rf_model <- randomForest(label ~. , data = feature_only,  ntree = 500, mtry = 9)
print(rf_model)
predictions <- predict(rf_model, feature_matrix)
confusionMatrix(predictions, feature_matrix$label)
var_imp = as.data.frame(importance(rf_model))
View(var_imp)
series = norm(100)
series = rnorm(100)
test = extract_all_features(series)
test$label = "Classical"
test_d = as.data.frame(unlist(test))
test_d$label = as.factor(test_d$label)
View(test_d)
test_d = t(test_d)
test_d$label = as.factor(test_d$label)
test_d = as.data.frame(test_d)
test_d$label = as.factor(test_d$label)
predict(rf_model, test_d)
devtools::load_all(".")
## create hypothetical data
data_test = list(series = rnorm(100), label = "Classical", T_length = 100, series_id = 1)
rm(test_d)
f_test = create_feature_dataset(data_test)
View(data_test)
data_test
create_feature_dataset(data_test)
data = data_test
n <- length(data$series)
feature_list <- vector("list", n)
message("Extracting features...")
n
## create hypothetical data
data_test = generate_series_multiple(n_per_model = 1, T_vals = 50, normalized = TRUE)
data_test
f_test = create_feature_dataset(data_test)
predict(rf_model, f_test)
devtools::load_all(".")
f_test = create_feature_dataset(data_test)
predict(rf_model, f_test)
f_test
f_test = as.data.frame(create_feature_dataset(data_test))
predict(rf_model, f_test)
rf_model
## create hypothetical data
data_test = generate_series_multiple(n_per_model = 1, T_vals = 100, normalized = TRUE)
f_test = as.data.frame(create_feature_dataset(data_test))
predict(rf_model, f_test)
f_test
f_test[grep("^logLik_", names(f_test))] <-
lapply(f_test[grep("^logLik_", names(f_test))], function(x) {
x[x < -1e5] <- -1e5#Inf
x[!is.finite(x)] <- -1e5
x
})
predict(rf_model, f_test)
f_test
predict(rf_model, f_test)
devtools::load_all(".")
# ----- 3. Build labeled feature_matrix of features ---------------------------------------
## --- Generate
simulated_data = generate_create_feature_dataset(n_per_model = 150, T_vals = c(100,150, 200), FALSE)
View(simulated_data)
feature_matrix  = as.data.frame(simulated_data$feature)
View(feature_matrix)
## fix LogLik values
feature_matrix[grep("^logLik_", names(feature_matrix))] <-
lapply(feature_matrix[grep("^logLik_", names(feature_matrix))], function(x) {
x[x < -1e5] <- -1e5#Inf
x[!is.finite(x)] <- -1e5
x
})
View(feature_matrix)
IRkernel::installspec()
install.packages("devtools")
install.packages("devtools")
IRkernel::installspec()
devtools::install_github("IRkernel/IRkernel")
devtools::install_github("IRkernel/IRkernel")
install_github("IRkernel/IRkernel")
devtools::install_github("IRkernel/IRkernel")
plot(cars)
2+1
raw_data = generate_series_multiple(n_per_model = 1, T_vals = 100, normalized = TRUE)
raw_data = Records::generate_series_multiple(n_per_model = 1, T_vals = 100, normalized = TRUE)
library(Records)
raw_data = simulated_data$data
s= raw_data$series[[1]]
n=length(s)
# trend: linear slope and p-value
time <- seq_len(n)
lmfit <- lm(s ~ time)
slope <- as.numeric(coef(lmfit)[2])
slope_pval <- summary(lmfit)$coefficients[2, 4]
slope_R2 <- summary(lmfit)
summary(lmfit)
slope_R2 <- summary(lmfit)$r.squared
ifelse(slope_pval < 0.05, slope, 0)
lm(s ~ seq_len(n))
lm(s ~ seq_len(n))
## 3 - Increments stat: First-order difference
ds <- diff(s)
mean_diff <- mean(ds)
std_diff  <- sd(ds)
signs <- sign(ds)
sign_changes <- sum(signs[-1] * signs[-length(signs)] < 0)
sign_change_rate <- sign_changes / (length(s) - 2)
sign_change_rate
sum(signs[-1] * signs[-length(signs)] < 0) / (length(s) - 2)
rec_counts(s)
rec_count(s)
devtools::load_all(".")
devtools::load_all(".")
library(devtools)
devtools::load_all(".")
install.packages(c("abind", "actuar", "anytime", "arrow", "BH", "bit", "bit64", "bmp", "broom", "bslib", "car", "checkmate", "cli", "clock", "colorspace", "commonmark", "copula", "corrr", "cowplot", "cpp11", "credentials", "crosstalk", "cubature", "curl", "data.table", "dbplyr", "dendextend", "DEoptimR", "Deriv", "DescTools", "diffobj", "digest", "diptest", "doBy", "downlit", "downloader", "DT", "dtplyr", "e1071", "elliptic", "emmeans", "evd", "expint", "expm", "fabletools", "FactoMineR", "fansi", "fdrtool", "feasts", "fitdistrplus", "fontawesome", "forcats", "future", "future.apply", "gargle", "GB2", "gclus", "generics", "gert", "GGally", "ggbeeswarm", "ggbrace", "ggdist", "ggforce", "ggplot2", "ggpubr", "ggridges", "ggsci", "ggstats", "gh", "gld", "glmnet", "globals", "glue", "gmp", "googledrive", "googlesheets4", "GPArotation", "gplots", "gumbel", "hardhat", "haven", "here", "Hmisc", "hms", "htmltools", "httpuv", "httr2", "hypergeo", "igraph", "imager", "inline", "isoband", "jpeg", "jsonlite", "knitr", "labelled", "later", "lava", "lavaan", "listenv", "lme4", "lmom", "lpSolveAPI", "lubridate", "magrittr", "MatrixModels", "matrixStats", "mclust", "mgcv", "mi", "microbenchmark", "mime", "minqa", "modeltools", "multcomp", "mvtnorm", "nloptr", "OpenMx", "openssl", "openxlsx", "ordinal", "parallelly", "party", "partykit", "patchwork", "pbapply", "pbkrtest", "pcaPP", "permute", "pillar", "posterior", "pracma", "pROC", "prodlim", "progressr", "promises", "pspline", "psych", "purrr", "quantmod", "quantreg", "questionr", "QuickJSR", "rbibutils", "rcartocolor", "Rcpp", "RcppArmadillo", "RcppEigen", "RcppParallel", "Rdpack", "readr", "readstata13", "readxl", "recipes", "reshape", "reshape2", "reticulate", "rlang", "rmarkdown", "robustbase", "rpart", "rpf", "rrcov", "rstan", "rstantools", "rstatix", "rstudioapi", "RUnit", "rversions", "rvest", "Ryacas0", "sandwich", "sass", "scales", "selectr", "semPlot", "seriation", "shiny", "slam", "slider", "SparseM", "stabledist", "stringi", "stringr", "styler", "survey", "survival", "systemfonts", "textshaping", "TH.data", "theft", "theftdlc", "tibble", "timeDate", "tinytex", "tseries", "TSP", "tzdb", "utf8", "vegan", "VGAM", "vroom", "warp", "WaveletComp", "WDI", "writexl", "xfun", "xgboost", "xlsxjars", "XML", "xml2", "xts", "yaml", "zip"))
install.packages(c("boot", "class", "cluster", "foreign", "KernSmooth", "lattice", "MASS", "Matrix", "nlme", "nnet", "spatial"))
devtools::load_all(".")
install.packages("cli")
install.packages("cli")
install.packages("cli", dependencies = TRUE)
install.packages("remotes")
remotes::install_github("r-lib/cli")
.libPaths()
packageVersion("cli")
.libPaths()
Sys.getenv("R_LIBS_USER")
install.packages("cli", lib = "C:/Users/User/AppData/Local/R/win-library/4.4")
devtools::load_all(".")
s = rnorm(100)
## 1 - Basic stats of the series
ave  <- mean(s)
n <- length(s)
med  <- median(s)
std  <- sd(s)
iqrv <- IQR(s)
minv <- min(s)
maxv <- max(s)
rng  <- maxv - minv
cv   <- sd(s)/mean(s)
skew <- ifelse(length(na.omit(s))>2, moments::skewness(s), NA)
kurt <- ifelse(length(na.omit(s))>3, moments::kurtosis(s), NA) # excess? moments::kurtosis returns fisher or pearson? okay
## 2 - trend: trend slope and R^2
lmfit <- lm(s ~ seq_len(n))
slope <- as.numeric(coef(lmfit)[2])
slope_pval <- summary(lmfit)$coefficients[2, 4]
slope_R2 <- summary(lmfit)$r.squared
kendall_tau <- cor(time, s, method = "kendall")  ##Mann-Kendall proxy: Kendall correlation between time and series
kendall_tau <- cor(seq_len(n), s, method = "kendall")  ##Mann-Kendall proxy: Kendall correlation between time and series
## 3 - Increments stat: First-order difference
ds <- diff(s)
len_ds <- length(ds)
mean_diff <- mean(ds)
std_diff  <- sd(ds)
signs <- sign(ds)
sign_change_rate <- sum(signs[-1] * signs[-length(signs)] < 0) / (length(s) - 2)
## 3 - Record Number info
rec_nb = rec_count(s)     ## number of records
