---
title: "Classification"
author: "Jinane Jouni"
date: "2025-12-20"
output: html_document
---
# ----- 0. Setup ---------------------------------------------------
Let numbers display in decimals and not scientific notation
```{r option}
options(scipen = 999)
```

Set seed also
```{r set seed}
set.seed(12345)
```

Library Records is essential to run most of the functions available on github.

To install
```{r install Records}
## library Records from Github
#devtools::install_github("jj-64/Records")
```

Load library
```{r load Records}
#library(Records)
devtools::load_all(".")
```


Check for required packages for install and loading
```{r load packages, message=FALSE, warning=TRUE, include=FALSE}
required_packages <- c(
  "tidyverse", 
  "moments", # skewness, kurtosis
  "dplyr", "tibble", "stats", 
  "factoextra", "FactoMineR",  ##PCA and visualization
  "corrplot", # correlation visualization
  "psych",        # describe()
  "GGally",       # ggpairs
  "matrixStats"  # fast row/column stats
)
## install if missing
install_if_missing(required_packages)

## Load libraries
load_package(required_packages = required_packages)

## Set caret parallel if desired (commented out by default)
# library(doParallel)
# cl <- makeCluster(detectCores() - 1); registerDoParallel(cl)
```

# ----- 1. Load data ---------------------------------------

Load feature matrix
```{r load feature matrix}
## For oneline users
#data("feature_matrix", package = "Records")

## Locally
data("feature_matrix")
data("feature_only")
```

Promise data
```{r see data}
str(feature_matrix)
```
Train–test split (shared across three models)

Use the same split for both matrices to ensure differences are attributable to feature cleaning only.
```{r train-test split}
feature_only$regime = feature_matrix$label

train_idx <- createDataPartition(feature_only$regime , p = 0.7, list = FALSE)

train_full <- feature_only[train_idx, ]
test_full  <- feature_only[-train_idx, ]
```


# ----- Model 1: Original Matrix -----------------

Random Forest on the original matrix
```{r Rf original}
rf_full <- randomForest::randomForest(
  regime ~ .,
  data = train_full,
  ntree = 1000,
  importance = TRUE
)
```

Performance evaluation
```{r Performance original}
pred_full <- predict(rf_full, newdata = test_full)
confusionMatrix(pred_full, test_full$regime)
```

Store metric
```{r Accuracy original}
acc_full <- confusionMatrix(pred_full, test_full$regime)$overall["Accuracy"]

```


# ----- 2. Variable importance analysis (original matrix) ----------

Extract importance
```{r Extract importance}
imp_full <- randomForest::importance(rf_full, type = 1)  # Mean Decrease Accuracy
imp_full <- data.frame(
  feature = rownames(imp_full),
  MDA = imp_full[, 1]
) %>% arrange(desc(MDA))
```

Visual inspection

      Interpretation:

      Near-zero or negative MDA → strong candidates for redundancy

      Highly correlated features often split importance

      Features important only deep in trees are often unstable
```{r Visual importance}
randomForest::varImpPlot(rf_full, type = 1, n.var = 30)
```
```{r variable importance}
rf_full$importance %>% as.data.frame %>% arrange(MeanDecreaseAccuracy) %>%
   select(MeanDecreaseAccuracy)
```

# ----- 3. Cleaning strategy (data-driven, RF-consistent) --------
Remove low-importance features

Define a conservative threshold (example: bottom 20%):

```{r Remove low-importance features}
threshold <- quantile(imp_full$MDA, 0.20)

remove_features_RF <- imp_full %>%
  filter(MDA < threshold) %>%
  pull(feature)
```

Create cleaned dataset:
```{r Create cleaned dataset}
df_clean_RF <- feature_only %>%
  select(-all_of(remove_features_RF))
```


Use the same split:
```{r split cleaned data}
train_clean_RF <- df_clean_RF[train_idx, ]
test_clean_RF  <- df_clean_RF[-train_idx, ]
```

Random Forest on the cleaned feature matrix 
Fit model

```{r fit model on RF cleaned}
rf_clean <- randomForest::randomForest(
  regime ~ .,
  data = train_clean_RF,
  ntree = 1000,
  importance = TRUE
)
```

6.2 Performance evaluation
```{r Performance RF clean}
pred_clean_RF <- predict(rf_clean, newdata = test_clean_RF)
confusionMatrix(pred_clean_RF, test_clean_RF$regime)
```

Store accuracy:
```{r Accuracy RF clean}
acc_clean_RF <- confusionMatrix(pred_clean_RF, test_clean_RF$regime)$overall["Accuracy"]
```


# ----- 4. Cleaning strategy (Desc analysis) --------

Remove low-importance features according to descriptive stat

```{r Remove low-importance features}

remove_features <- c( "garch_acf", "garch_r2",
                       "local_maxima", "local_minima",
                       "sign_change_rate",
                       "dom_power", "min",
                       "cv", "diff_mean",
                       "median", "std" ,
                       "diff_sd",
                       "diff_skew","range","rolling_var_instab.var_instab"
                       )
```

Create cleaned dataset:
```{r Create cleaned dataset 2}
df_clean <- feature_only %>%
  select(-all_of(remove_features))
```


Use the same split:
```{r split cleaned data}
train_clean <- df_clean[train_idx, ]
test_clean <- df_clean[-train_idx, ]
```

Random Forest on the cleaned feature matrix 
Fit model

```{r fit model on desc cleaned}
rf_clean_desc <- randomForest::randomForest(
  regime ~ .,
  data = train_clean,
  ntree = 1000,
  importance = TRUE
)
```

6.2 Performance evaluation
```{r}
pred_clean <- predict(rf_clean_desc, newdata = test_clean)
confusionMatrix(pred_clean, test_clean$regime)
```

Store accuracy:
```{r}
acc_clean_desc <- confusionMatrix(pred_clean, test_clean$regime)$overall["Accuracy"]
```


# ----- 5. Direct comparison -----------------

comparison

    Key outcomes to interpret
    
    Same or higher accuracy with fewer features → redundancy confirmed
    
    Accuracy drop → removed features contained complementary signal
    
    Accuracy increase → noise reduction / variance control
    
```{r comparison acc}
comparison <- data.frame(
  Model = c("Original", "Cleaned_RF", "Cleaned_desc"),
  Accuracy = c(acc_full, acc_clean_RF, acc_clean_desc),
  Num_Features = c(
    ncol(train_full) - 1,
    ncol(train_clean_RF) - 1,
     ncol(train_clean) - 1
  )
)

print(comparison)
```

Removed features
```{r removed features compare}
# print("Remove features according to VarImp")
# print(remove_features_RF)
# 
# 
# print("Remove features according to descriptive")
# print(remove_features)

## common features
intersect(remove_features, remove_features_RF)
```

# -----8. Redundancy diagnostics (recommended) -------
8.1 Correlation among top features
      
      Highly correlated important variables suggest:

      Exchangeability

      Potential for further dimensional reduction

```{r}
imp_clean <- randomForest::importance(rf_clean_desc, type = 1)  # Mean Decrease Accuracy
imp_clean <- data.frame(
  feature = rownames(imp_clean),
  MDA = imp_clean[, 1]
) %>% arrange(desc(MDA))

top_feats <- head(imp_clean$feature, 20)
cor_mat <- cor(train_clean[, top_feats])

high_corr <- which(abs(cor_mat) > 0.95 & abs(cor_mat) < 1, arr.ind = TRUE) 

high_corr_pairs <- tibble(
  feature_1 = rownames(cor_mat)[high_corr[,1]],
  feature_2 = colnames(cor_mat)[high_corr[,2]],
  rho = cor_mat[high_corr]
   ) %>% dplyr::filter(feature_1 != feature_2)

print(high_corr_pairs)

```

# ----- Importance stability check (optional but strong) --------------


High SD = unstable importance = weak justification for inclusion.
```{repeat rf}
rf_repeat <- replicate(
  50,
  randomForest(regime ~ ., data = train_clean, ntree = 500, importance = TRUE),
  simplify = FALSE
)

imp_stability <- sapply(rf_repeat, function(m)
  importance(m, type = 1)[, 1])

imp_sd <- apply(imp_stability, 1, sd)
 print(imp_sd)
```
# -------- Test on one series --------------------------

```{r test series}
series_single = LDM_series(100, 0.2, "gumbel", loc=0, scale=1)
series_single_feature = extract_all_features(series_single) %>% as.data.frame()
```

```{r remove -Inf for logLik}
series_single_feature[grep("^logLik_", names(series_single_feature))] <-
  lapply(series_single_feature[grep("^logLik_", names(series_single_feature))], function(x) {
    x[x < -1e5] <- -1e5#Inf
    x[!is.finite(x)] <- -1e5
    x
  })
```

```{r}
predict(rf_clean, series_single_feature)
```
# -------- Test on multiple series --------------------------

```{r test series}
series = generate_series_multiple(n_per_model = 5, T_vals = c(100))
```


```{r feature series}
series_feature = as.data.frame(create_feature_dataset(series))
```

```{r remove -Inf for logLik}
series_feature[grep("^logLik_", names(series_feature))] <-
  lapply(series_feature[grep("^logLik_", names(series_feature))], function(x) {
    x[x < -1e5] <- -1e5#Inf
    x[!is.finite(x)] <- -1e5
    x
  })
```

```{r}
predicted_series = predict(rf_full, series_feature)
```

```{r compare predict}
table(predicted_series, series_feature$label)
```
