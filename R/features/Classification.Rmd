---
title: "Classification"
author: "Jinane Jouni"
date: "2025-12-20"
output: html_document
---
# ----- 0. Setup ---------------------------------------------------
Let numbers display in decimals and not scientific notation
```{r option}
options(scipen = 999)
```

Set seed also
```{r set seed}
set.seed(12345)
```

Library Records is essential to run most of the functions available on github.

To install
```{r install Records}
## library Records from Github
#devtools::install_github("jj-64/Records")
```

Load library
```{r load Records}
#library(Records)
devtools::load_all(".")
```


Check for required packages for install and loading
```{r load packages, message=FALSE, warning=TRUE, include=FALSE}
required_packages <- c(
  "tidyverse", 
  "moments", # skewness, kurtosis
  "dplyr", "tibble", "stats", 
  "factoextra", "FactoMineR",  ##PCA and visualization
  "corrplot", # correlation visualization
  "psych",        # describe()
  "GGally",       # ggpairs
  "matrixStats"  # fast row/column stats
)
## install if missing
install_if_missing(required_packages)

## Load libraries
load_package(required_packages = required_packages)

## Set caret parallel if desired (commented out by default)
library(doParallel)
# cl <- makeCluster(detectCores() - 1); registerDoParallel(cl)
```

# ----- 1. Load data ---------------------------------------

Load feature matrix
```{r load feature matrix}
## For oneline users
#data("feature_matrix", package = "Records")

## Locally
data("feature_matrix")
```

Promise data
```{r see data}
str(feature_matrix)
```
Train–test split (shared across models)

Use the same split for both matrices to ensure differences are attributable to feature cleaning only.
```{r}
train_idx <- createDataPartition(df_full$y, p = 0.7, list = FALSE)

train_full <- df_full[train_idx, ]
test_full  <- df_full[-train_idx, ]
```


Random Forest on the original  matrix
```{r}
rf_full <- randomForest(
  y ~ .,
  data = train_full,
  ntree = 1000,
  importance = TRUE
)
```

Performance evaluation
```{r}
pred_full <- predict(rf_full, newdata = test_full)
confusionMatrix(pred_full, test_full$y)
```

Store metric
```{r}
acc_full <- confusionMatrix(pred_full, test_full$y)$overall["Accuracy"]

```




4. Variable importance analysis (original matrix)
4.1 Extract importance
imp_full <- importance(rf_full, type = 1)  # Mean Decrease Accuracy
imp_full <- data.frame(
  feature = rownames(imp_full),
  MDA = imp_full[, 1]
) %>% arrange(desc(MDA))

4.2 Visual inspection
varImpPlot(rf_full, type = 1, n.var = 20)


Interpretation guidance

Near-zero or negative MDA → strong candidates for redundancy

Highly correlated features often split importance

Features important only deep in trees are often unstable

5. Cleaning strategy (data-driven, RF-consistent)
5.1 Remove low-importance features

Define a conservative threshold (example: bottom 20%):

threshold <- quantile(imp_full$MDA, 0.20)

selected_features <- imp_full %>%
  filter(MDA > threshold) %>%
  pull(feature)


Create cleaned dataset:

df_clean <- df_full %>%
  select(all_of(selected_features), y)


Use the same split:

train_clean <- df_clean[train_idx, ]
test_clean  <- df_clean[-train_idx, ]

6. Random Forest on the cleaned feature matrix
6.1 Fit model
rf_clean <- randomForest(
  y ~ .,
  data = train_clean,
  ntree = 1000,
  importance = TRUE
)

6.2 Performance evaluation
pred_clean <- predict(rf_clean, newdata = test_clean)
confusionMatrix(pred_clean, test_clean$y)


Store accuracy:

acc_clean <- confusionMatrix(pred_clean, test_clean$y)$overall["Accuracy"]

7. Direct comparison
comparison <- data.frame(
  Model = c("Original", "Cleaned"),
  Accuracy = c(acc_full, acc_clean),
  Num_Features = c(
    ncol(train_full) - 1,
    ncol(train_clean) - 1
  )
)

comparison


Key outcomes to interpret

Same or higher accuracy with fewer features → redundancy confirmed

Accuracy drop → removed features contained complementary signal

Accuracy increase → noise reduction / variance control

8. Redundancy diagnostics (recommended)
8.1 Correlation among top features
top_feats <- head(imp_full$feature, 20)
cor_mat <- cor(train_full[, top_feats])


Highly correlated important variables suggest:

Exchangeability

Potential for further dimensional reduction

8.2 Importance stability check (optional but strong)
set.seed(1)
rf_repeat <- replicate(
  20,
  randomForest(y ~ ., data = train_full, ntree = 500, importance = TRUE),
  simplify = FALSE
)

imp_stability <- sapply(rf_repeat, function(m)
  importance(m, type = 1)[, 1])

imp_sd <- apply(imp_stability, 1, sd)


High SD = unstable importance = weak justification for inclusion.
